ci = list(
lower = assoc_lower,
point = assoc_point,
upper = assoc_upper
)
)
}
list(id = x$id, metadata = x$metadata, data = data)
}
tmp <- Map(addData, rowwise_id_metadata)
tmp
set.seed(12)
addData <- function(x){
if (isDataless(x)){
data = NULL
} else {
# We now want to extend this a bit more ...
# set.seed(12)
#
#
# # z scores of point estimates are from standard normal distribution
main_val_z <- rnorm(1)
#
# These are now converted to probability scale
main_val <- main_val_z |> inv_logit()
#
# # The amount of variation is modelled from an exponential distribution, as it cannot be negative
assoc_se_z <- rexp(1, rate = 5)
#
# # For intervals want to +/- 2 * the z value of assoc_se_z to main_vals_z
# # then do inv_logit to get to probability scale
#
assoc_lower_z <- main_val_z - 2 * assoc_se_z
assoc_upper_z <- main_val_z + 2 * assoc_se_z
#
assoc_lower <- inv_logit(assoc_lower_z)
assoc_upper <- inv_logit(assoc_upper_z)
#
assoc_point <- main_val
#
# # For representing changes over time, we'll take the last value, and add a smaller random amount multiple times to get a random walk backwards
#
# We need the z_value, call this z_0
z_0 <- main_val_z
t_vals <- 1:10
z_vals <- vector("numeric", 10)
# Create a trend component
trend_z <- rnorm(1, 0, 0.2)
for (i in 2:10){
noise_z <- rnorm(1, 0, 0.05)
next_z <- z_vals[i-1] + trend_z + noise_z
z_vals[i] <- next_z
}
y_vals <- inv_logit(z_vals)
df_ts <- data.frame(
t = t_vals,
y = y_vals
)
data = list(
main = main_val,
ci = list(
lower = assoc_lower,
point = assoc_point,
upper = assoc_upper
),
time_series =
df_ts
)
}
list(id = x$id, metadata = x$metadata, data = data)
}
tmp <- Map(addData, rowwise_id_metadata)
tmp
tmp[[5]]
set.seed(12)
addData <- function(x){
if (isDataless(x)){
data = NULL
} else {
# We now want to extend this a bit more ...
# set.seed(12)
#
#
# # z scores of point estimates are from standard normal distribution
main_val_z <- rnorm(1)
#
# These are now converted to probability scale
main_val <- main_val_z |> inv_logit()
#
# # The amount of variation is modelled from an exponential distribution, as it cannot be negative
assoc_se_z <- rexp(1, rate = 5)
#
# # For intervals want to +/- 2 * the z value of assoc_se_z to main_vals_z
# # then do inv_logit to get to probability scale
#
assoc_lower_z <- main_val_z - 2 * assoc_se_z
assoc_upper_z <- main_val_z + 2 * assoc_se_z
#
assoc_lower <- inv_logit(assoc_lower_z)
assoc_upper <- inv_logit(assoc_upper_z)
#
assoc_point <- main_val
#
# # For representing changes over time, we'll take the last value, and add a smaller random amount multiple times to get a random walk backwards
#
# We need the z_value, call this z_0
z_0 <- main_val_z
t_vals <- 1:10
z_vals <- vector("numeric", 10)
# Create a trend component
trend_z <- rnorm(1, 0, 0.2)
for (i in 2:10){
noise_z <- rnorm(1, 0, 0.05)
next_z <- z_vals[i-1] + trend_z * (i-1) + noise_z
z_vals[i] <- next_z
}
y_vals <- inv_logit(z_vals)
df_ts <- data.frame(
t = t_vals,
y = y_vals
)
data = list(
main = main_val,
ci = list(
lower = assoc_lower,
point = assoc_point,
upper = assoc_upper
),
time_series =
df_ts
)
}
list(id = x$id, metadata = x$metadata, data = data)
}
tmp <- Map(addData, rowwise_id_metadata)
tmp[[3]]
tmp[[4]]
set.seed(12)
addData <- function(x){
if (isDataless(x)){
data = NULL
} else {
# We now want to extend this a bit more ...
# set.seed(12)
#
#
# # z scores of point estimates are from standard normal distribution
main_val_z <- rnorm(1)
#
# These are now converted to probability scale
main_val <- main_val_z |> inv_logit()
#
# # The amount of variation is modelled from an exponential distribution, as it cannot be negative
assoc_se_z <- rexp(1, rate = 5)
#
# # For intervals want to +/- 2 * the z value of assoc_se_z to main_vals_z
# # then do inv_logit to get to probability scale
#
assoc_lower_z <- main_val_z - 2 * assoc_se_z
assoc_upper_z <- main_val_z + 2 * assoc_se_z
#
assoc_lower <- inv_logit(assoc_lower_z)
assoc_upper <- inv_logit(assoc_upper_z)
#
assoc_point <- main_val
#
# # For representing changes over time, we'll take the last value, and add a smaller random amount multiple times to get a random walk backwards
#
# We need the z_value, call this z_0
z_0 <- main_val_z
t_vals <- 1:10
z_vals <- vector("numeric", 10)
z_vals[1] <- z_0
# Create a trend component
trend_z <- rnorm(1, 0, 0.2)
for (i in 2:10){
noise_z <- rnorm(1, 0, 0.05)
next_z <- z_vals[i-1] + trend_z * (i-1) + noise_z
z_vals[i] <- next_z
}
y_vals <- inv_logit(z_vals)
df_ts <- data.frame(
t = t_vals,
y = y_vals
)
data = list(
main = main_val,
ci = list(
lower = assoc_lower,
point = assoc_point,
upper = assoc_upper
),
time_series =
df_ts
)
}
list(id = x$id, metadata = x$metadata, data = data)
}
tmp <- Map(addData, rowwise_id_metadata)
tmp
make_fake_data <- function(
time_periods = 10,
se_rate = 5,
trend_se = 0.02,
noise_se = 0.05
) {
# set.seed(12)
#
#
# # z scores of point estimates are from standard normal distribution
main_val_z <- rnorm(1)
#
# These are now converted to probability scale
main_val <- main_val_z |> inv_logit()
#
# # The amount of variation is modelled from an exponential distribution, as it cannot be negative
assoc_se_z <- rexp(1, rate = 5)
#
# # For intervals want to +/- 2 * the z value of assoc_se_z to main_vals_z
# # then do inv_logit to get to probability scale
#
assoc_lower_z <- main_val_z - 2 * assoc_se_z
assoc_upper_z <- main_val_z + 2 * assoc_se_z
#
assoc_lower <- inv_logit(assoc_lower_z)
assoc_upper <- inv_logit(assoc_upper_z)
#
assoc_point <- main_val
#
# # For representing changes over time, we'll take the last value, and add a smaller random amount multiple times to get a random walk backwards
#
# We need the z_value, call this z_0
z_0 <- main_val_z
t_vals <- 1:10
z_vals <- vector("numeric", 10)
z_vals[1] <- z_0
# Create a trend component
trend_z <- rnorm(1, 0, 0.2)
for (i in 2:10){
noise_z <- rnorm(1, 0, 0.05)
next_z <- z_vals[i-1] + trend_z * (i-1) + noise_z
z_vals[i] <- next_z
}
y_vals <- inv_logit(z_vals)
df_ts <- data.frame(
t = t_vals,
y = y_vals
)
data = list(
main = main_val,
ci = list(
lower = assoc_lower,
point = assoc_point,
upper = assoc_upper
),
time_series =
df_ts
)
data
}
addData <- function(x, useFakeData = TRUE){
if (isDataless(x)){
data = NULL
} else {
# We now want to extend this a bit more ...
if (useFakeData){
data = make_fake_data()
}
}
list(id = x$id, metadata = x$metadata, data = data)
}
tmp <- Map(addData, rowwise_id_metadata)
tmp
source("~/repos/mhi-cyp-backend/R/raggedifiers.R", echo=TRUE)
devtools::load_all(".")
# First read the dataframe from excel worksheet
indicator_information_df <- readxl::read_excel(here::here("inst/extdata/IndicatorInformation.xlsx"), sheet = "all_indicators")
# Then save this as indicator_informaiton_df
# usethis::use_data(indicator_information_df)
# Let's create a list object that is row-first
# The structure should be:
# for each row in indicator_information-df
# create an empty list
# in the empty list create an id object
# populate the object with id
# in the empty list create a metadata object
# populate the metadata with everything other than id
rowwise_id_metadata <- make_rowwise_id_metadata(indicator_information_df)
# Now check the contents of metadata$dataless
sapply(rowwise_id_metadata, isDataless)
# If the indicator is dataless, add no data
# Otherwise, add/generate data
set.seed(12)
rowwise_id_metadata_data_fake <- Map(addData, rowwise_id_metadata)
rowwise_id_metadata_data_fake
usethis::use_data(rowwise_id_metadata_data_fake)
devtools::load_all(".")
start_plumber()
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
rowwise_id_metadata_data_fake$id == 4
sapply(rowwise_id_metadata_data_fake, function(x) x$id == 4)
selector <- sapply(rowwise_id_metadata_data_fake, function(x) x$id == 4)
this_record <- rowwise_id_metadata_data_fake[[selector]]
this_record <- rowwise_id_metadata_data_fake[selector]
this_record
devtools::load_all(".")
start_plumber()
id <- 4
selector <-   selector <- sapply(rowwise_id_metadata_data_fake, function(x) x$id == id)
this_record <- rowwise_id_metadata_data_fake[selector]
this_record
this_record[[1]]
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
plumber::plumb(file='routes/plumber.R')$run()
rowwise_id_metadata_data_fake[[4]]$data
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
id <- 4
selector(sapply(rowwise_id_metadata_data_fake, function(x) x$id == id))
selector <- sapply(rowwise_id_metadata_data_fake, function(x) x$id == id)
this_record <- rowwise_id_metadata_data_fake[selector][[1]]
this_record
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
plumber::plumb(file='routes/plumber.R')$run()
devtools::load_all(".")
start_plumber()
?jsonlite::toJSON
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
tmp <- [
tmp <-
"{\"t\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.35,0.3352,0.3349,0.3185,0.2979,0.2642,0.2322,0.2126,0.1821,0.1429]}"
jsonlite::fromJSON(tmp)
jsonlite::fromJSON(tmp, simplifyDataFrame = TRUE)
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
devtools::load_all(".")
rowwise_id_metadata_data_fake
?str
rowwise_id_metadata_data_fake |> str(max_level = 1)
sapply(rowwise_id_metadata_data_fake, function(x) x$id)
sapply(rowwise_id_metadata_data_fake, function(x) x$id) |> length()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
mhi-cyp-backend::rowwise_id_metadata_data_fake
rowwise_id_metadata_data_fake
View(rowwise_id_metadata_data_fake)
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
tmp1 <- c(T, T, T, T)
tmp2 <- c(T, F, T, T)
tmp1 & tmp2
tmp3 <- tmp1 & tmp2
tmp4 <- c(T, T, F, T)
tmp5 <- tmp3 & tmp4
tmp5
sapply(rowwise_id_metadata_data_fake, function(x) x$metadata$domain)
sapply(rowwise_id_metadata_data_fake, function(x) x$metadata$domain) |> unique()
sapply(rowwise_id_metadata_data_fake, function(x) x$metadata$construct) |> unique()
sapply(rowwise_id_metadata_data_fake, function(x) x$metadata$domain) |> unique()
sapply(rowwise_id_metadata_data_fake, function(x) x$metadata$source) |> unique()
# First read the dataframe from excel worksheet
indicator_information_df <- readxl::read_excel(here::here("inst/extdata/IndicatorInformation.xlsx"), sheet = "all_indicators")
# Then save this as indicator_informaiton_df
# usethis::use_data(indicator_information_df)
# Let's create a list object that is row-first
# The structure should be:
# for each row in indicator_information-df
# create an empty list
# in the empty list create an id object
# populate the object with id
# in the empty list create a metadata object
# populate the metadata with everything other than id
rowwise_id_metadata <- make_rowwise_id_metadata(indicator_information_df)
# Now check the contents of metadata$dataless
sapply(rowwise_id_metadata, isDataless)
# If the indicator is dataless, add no data
# Otherwise, add/generate data
set.seed(12)
rowwise_id_metadata_data_fake <- Map(addData, rowwise_id_metadata)
usethis::use_data(rowwise_id_metadata_data_fake)
rowwise_id_metadata_data_fake
rowwise_id_metadata_data_fake[[1]]
rowwise_id_metadata_data_fake[[1]]$metadata
rowwise_id_metadata_data_fake[[1]]$metadata |> sapply(FUN = function(x) x$metadata$construct) |> unique()
rowwise_id_metadata_data_fake |> sapply(FUN = function(x) x$metadata$construct) |> unique()
devtools::load_all(".")
start_plumber()
start_plumber()
devtools::load_all(".")
start_plumber()
ids <- rowwise_id_metadata_data_fake
metadata <- sapply(rowwise_id_metadata_data_fake, fuction(x) x$metadata)
metadata <- sapply(rowwise_id_metadata_data_fake, function(x) x$metadata)
metadata
metadata <- sapply(rowwise_id_metadata_data_fake, function(x) x$metadata) |> t()
metadata
metadata
metadata |> tibble()
metadata |> tibble::tibble()
metadata |> tibble::tibble() |> view()
metadata |> tibble::tibble() |> View()
metadata |> tibble::as_tibble() |> View()
metadata |> tibble::as_tibble() |> dplyr::mutate(id = ids) |> dplyr::select(id, everything() |> View()
metadata |> tibble::as_tibble() |> dplyr::mutate(id = ids) |> dplyr::select(id, everything()) |> View()
ids
ids <- rowwise_id_metadata_data_fake |> sapply(FUN = function(x) x$id)
ids
metadata |> tibble::as_tibble() |> dplyr::mutate(id = ids) |> dplyr::select(id, everything())
metadata |> tibble::as_tibble()
metadata |> tibble::as_tibble()
metadata |> tibble::as_tibble() |> View()
metadata |> tibble::as_tibble()
rowwise_id_metadata_data_fake
rowwise_id_metadata_data_fake$metadata
tmp <- lapply(rowwise_id_metadata_data_fake, function(x) x$metadata)
tmp
tmp |> as.data.frame()
tmp |> t() |> as.data.frame()
tmp <- sapply(rowwise_id_metadata_data_fake, function(x) x$metadata)
tmp
tmp |> t() |> as.data.frame()
tmp |> t() |> as.data.frame() -> tmp2
tmp2
tmp3 <- data.frame(id = ids, tmp2)
tmp3
head(tmp3)
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
?serializer
plumber::serializer_rds()
devtools::load_all(".")
start_plumber()
?serializer
library(plumber)
?serialiser
?serializer
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber()
devtools::load_all(".")
start_plumber
start_plumber()
devtools::load_all(".")
start_plumber()
